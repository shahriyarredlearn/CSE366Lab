{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahriyarredlearn/CSE366Lab/blob/main/CSE366LAB3_Task_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtaBvDEGaFw6"
      },
      "outputs": [],
      "source": [
        "#importing all the necessery libraries\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#utilities\n",
        "\n",
        "def argmaxall(gen):\n",
        "    \"\"\"gen is a generator of (element,value) pairs, where value is a real.\n",
        "    argmaxall returns a list of all of the elements with maximal value.\n",
        "    \"\"\"\n",
        "    maxv = -math.inf       # negative infinity\n",
        "    maxvals = []      # list of maximal elements\n",
        "    for (e,v) in gen:\n",
        "        if v>maxv:\n",
        "            maxvals,maxv = [e], v\n",
        "        elif v==maxv:\n",
        "            maxvals.append(e)\n",
        "    return maxvals"
      ],
      "metadata": {
        "id": "4vagTifcaRq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def argmaxe(gen):\n",
        "    \"\"\"gen is a generator of (element,value) pairs, where value is a real.\n",
        "    argmaxe returns an element with maximal value.\n",
        "    If there are multiple elements with the max value, one is returned at random.\n",
        "    \"\"\"\n",
        "    return random.choice(argmaxall(gen))"
      ],
      "metadata": {
        "id": "u3Pz60lTaXHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def argmax(lst):\n",
        "    \"\"\"returns maximum index in a list\"\"\"\n",
        "    return argmaxe(enumerate(lst))"
      ],
      "metadata": {
        "id": "AMhoizcZaYI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def argmaxd(dct):\n",
        "   \"\"\"returns the arg max of a dictionary dct\"\"\"\n",
        "   return argmaxe(dct.items())"
      ],
      "metadata": {
        "id": "KqqYeGW1aZKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flip(prob):\n",
        "    \"\"\"return true with probability prob\"\"\"\n",
        "    return random.random() < prob"
      ],
      "metadata": {
        "id": "YM2lgM_baagM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_from_dist(item_prob_dist):\n",
        "  #{6:0.1, 5:0.1, 4:0.1, 3:0.3, 2:0.2, 1:0.2}\n",
        "    \"\"\" returns a value from a distribution.\n",
        "    item_prob_dist is an item:probability dictionary, where the\n",
        "        probabilities sum to 1.\n",
        "    returns an item chosen in proportion to its probability\n",
        "    \"\"\"\n",
        "    ranreal = random.random()\n",
        "    for (it,prob) in item_prob_dist.items():\n",
        "        if ranreal < prob:\n",
        "            return it\n",
        "        else:\n",
        "            ranreal -= prob\n",
        "    raise RuntimeError(f\"{item_prob_dist} is not a probability distribution\")"
      ],
      "metadata": {
        "id": "Bo7IBUM2abd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Displayable(object):\n",
        "    \"\"\"Class that uses 'display'.\n",
        "    The amount of detail is controlled by max_display_level\n",
        "    \"\"\"\n",
        "    max_display_level = 1   # can be overridden in subclasses or instances\n",
        "\n",
        "    def display(self,level,*args,**nargs):\n",
        "        \"\"\"print the arguments if level is less than or equal to the\n",
        "        current max_display_level.\n",
        "        level is an integer.\n",
        "        the other arguments are whatever arguments print can take.\n",
        "        \"\"\"\n",
        "\n",
        "        if level <= self.max_display_level:\n",
        "            print(*args, **nargs)  ##if error you are using Python2 not Python3\n"
      ],
      "metadata": {
        "id": "Df72uGmSadCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Plot_history(object):\n",
        "    \"\"\"Set up the plot for history of price and number in stock\"\"\"\n",
        "    def __init__(self, ag, env):\n",
        "        self.ag = ag\n",
        "        self.env = env\n",
        "        plt.ion()\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"Value\")\n",
        "\n",
        "\n",
        "    def plot_env_hist(self):\n",
        "        \"\"\"plot history of price and instock\"\"\"\n",
        "        num = len(env.stock_history)\n",
        "        plt.plot(range(num),env.price_history,label=\"Price\")\n",
        "        plt.plot(range(num),env.stock_history,label=\"In stock\")\n",
        "        plt.legend()\n",
        "        #plt.draw()\n",
        "\n",
        "    def plot_agent_hist(self):\n",
        "        \"\"\"plot history of buying\"\"\"\n",
        "        num = len(ag.buy_history)\n",
        "        plt.bar(range(1,num+1), ag.buy_history, label=\"Bought\")\n",
        "        plt.legend()\n",
        "        #plt.draw()"
      ],
      "metadata": {
        "id": "XPP97RfeaeXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Agent Controller**"
      ],
      "metadata": {
        "id": "QjvTV5V5ak0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from display import Displayable\n",
        "\n",
        "class Agent(Displayable):\n",
        "\n",
        "    def initial_action(self, percept):\n",
        "        \"\"\"return the initial action.\"\"\"\n",
        "        return self.select_action(percept)   # same as select_action\n",
        "\n",
        "    def select_action(self, percept):\n",
        "        \"\"\"return the next action (and update internal state) given percept\n",
        "        percept is variable:value dictionary\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"go\")   # abstract method"
      ],
      "metadata": {
        "id": "cUaVCjjmageM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agent Virtual Environment"
      ],
      "metadata": {
        "id": "COQcB1y9arhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Environment(Displayable):\n",
        "    def initial_percept(self):\n",
        "        \"\"\"returns the initial percept for the agent\"\"\"\n",
        "        raise NotImplementedError(\"initial_percept\")   # abstract method\n",
        "\n",
        "    def do(self, action):\n",
        "        \"\"\"does the action in the environment\n",
        "        returns the next percept \"\"\"\n",
        "        raise NotImplementedError(\"Environment.do\")   # abstract method"
      ],
      "metadata": {
        "id": "-vKqdB61awxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simulation of the realworld task"
      ],
      "metadata": {
        "id": "V25LOZVAayz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Simulate(Displayable):\n",
        "    \"\"\"simulate the interaction between the agent and the environment\n",
        "    for n time steps.\n",
        "    Returns a pair of the agent state and the environment state.\n",
        "    \"\"\"\n",
        "    def __init__(self,agent, environment):\n",
        "        self.agent = agent\n",
        "        self.env = environment\n",
        "        self.percept = self.env.initial_percept()\n",
        "        self.percept_history = [self.percept]\n",
        "        self.action_history = []\n",
        "\n",
        "    def go(self, n):\n",
        "        for i in range(n):\n",
        "            action = self.agent.select_action(self.percept)\n",
        "            print(f\"i={i} action={action}\")\n",
        "\n",
        "            self.percept = self.env.do(action,i)\n",
        "            print(f\"      percept={self.percept}\")"
      ],
      "metadata": {
        "id": "JfT-GgA4a5Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TP_env(Environment):\n",
        "    price_delta = [0, 0, 0, 21, 0, 20, 0, -64, 0, 0, 23, 0, 0, 0, -35,\n",
        "        0, 76, 0, -41, 0, 0, 0, 21, 0, 5, 0, 5, 0, 0, 0, 5, 0, -15, 0, 5,\n",
        "       0, 5, 0, -115, 0, 115, 0, 5, 0, -15, 0, 5, 0, 5, 0, 0, 0, 5, 0,\n",
        "       -59, 0, 44, 0, 5, 0, 5, 0, 0, 0, 5, 0, -65, 50, 0, 5, 0, 5, 0, 0,\n",
        "       0, 5, 0]\n",
        "    sd = 5  # noise standard deviation\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"paper buying agent\"\"\"\n",
        "        self.time=0\n",
        "        self.stock=20\n",
        "        self.stock_history = []  # memory of the stock history\n",
        "        self.price_history = []  # memory of the price history\n",
        "\n",
        "    def initial_percept(self):\n",
        "        \"\"\"return initial percept\"\"\"\n",
        "        self.stock_history.append(self.stock)\n",
        "        self.price = round(234+self.sd*random.gauss(0,1))\n",
        "        self.price_history.append(self.price)\n",
        "        #print(f\"Initial price: {self.price} ,instock: {self.stock}\")\n",
        "        return {'price': self.price,\n",
        "                'instock': self.stock}\n",
        "\n",
        "    def do(self, action, time_unit):\n",
        "        \"\"\"does action (buy) and returns percept consisting of price and instock\"\"\"\n",
        "        used = select_from_dist({6:0.1, 5:0.1, 4:0.1, 3:0.3, 2:0.2, 1:0.2})\n",
        "        print(f\"i={time_unit} used={used}\")\n",
        "        # used = select_from_dist({7:0.1, 6:0.2, 5:0.2, 4:0.3, 3:0.1, 2:0.1}) # uses more paper\n",
        "        bought = action['buy']\n",
        "        self.stock = self.stock+bought-used\n",
        "        self.stock_history.append(self.stock)\n",
        "        self.time += 1\n",
        "        self.price =  round(self.price\n",
        "                        + self.price_delta[self.time%len(self.price_delta)] # repeating pattern\n",
        "                        + self.sd*random.gauss(0,1)) # plus randomness\n",
        "        self.price_history.append(self.price)\n",
        "        return {'price': self.price,\n",
        "                'instock': self.stock}"
      ],
      "metadata": {
        "id": "fuPqcxVGa7Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TP_agent(Agent):\n",
        "    def __init__(self):\n",
        "        self.spent = 0\n",
        "        percept = env.initial_percept()\n",
        "        self.ave = self.last_price = percept['price']\n",
        "        self.instock = percept['instock']\n",
        "        self.buy_history = []\n",
        "\n",
        "    def select_action(self, percept):\n",
        "        \"\"\"return next action to carry out\n",
        "        \"\"\"\n",
        "        self.last_price = percept['price']\n",
        "        self.ave = self.ave+(self.last_price-self.ave)*0.05\n",
        "        self.instock = percept['instock']\n",
        "        if self.last_price < 0.2*self.ave and self.instock < 20:\n",
        "            tobuy = 15\n",
        "        elif self.instock < 10:\n",
        "            tobuy = 10\n",
        "        else:\n",
        "            tobuy = 0\n",
        "        self.spent += tobuy*self.last_price\n",
        "        self.buy_history.append(tobuy)\n",
        "        #print(f\"agent buy:{tobuy}\")\n",
        "        return {'buy': tobuy}"
      ],
      "metadata": {
        "id": "OnYZ2um9a9JX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = TP_env()\n",
        "ag = TP_agent()\n",
        "sim = Simulate(ag,env)\n",
        "sim.go(10)\n",
        "ag.spent/env.time"
      ],
      "metadata": {
        "id": "Ep2RzBnba-Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sim.go(100);"
      ],
      "metadata": {
        "id": "ySPLDBmea_yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sim.go(100);\n",
        "print(f\"agent spent ${ag.spent/100}\")\n",
        "pl = Plot_history(ag,env); pl.plot_env_hist(); pl.plot_agent_hist()"
      ],
      "metadata": {
        "id": "n4WQ1m6KbAjJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}